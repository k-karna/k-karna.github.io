---
layout: article
title: Contrastive Learning
tags: self-supervised-learning contrastive-learning
date: 2023-12-28
sidebar:
  nav: "docs-en"
mathjax: true
mathjax_autoNumber: true
---

## Momentum Contrast (MoCo)

In Contrastive Learning, from the representation of an augmented view of an image, our network learns to discriminate between the representation of another augmented view of the same image, and the representation of augmented view of a different image. This learning requires comparison between the representation of an augmented view and many negative samples.

For this, __Momentum Contrast (MoCo)__ borrowed the idea of tokenized dictionaries from BERT (He et al., 2020). In MoCo, we have the query representation $q$, expressed as $q = f_q(x^q)$ where $f_q$ is encoder network and $x^q$ is an encoder query sample. Similarly, on the other side, we have a set of encoded samples ${k_0, k_1, k_2, ... }$ expressed as $k = f_k(x^k)$ where $f_k$ is key encoder and $x^k$ is a sample to be compared against.

As we are comparing representation of another augmentation of same image with representation of augmentations of different image, let's assume we have only single key $k_{+}$ in dictionary matching $q$ query. Then, our network needs to classify $q$ as $k_{+}$. For this, MoCo uses contrastive loss called InfoNCE, where value of loss function is low when $q$ is compared to its similar key $k_{+}$ and large when compared to other dissimilar keys. Contrastive loss, InfoNCE is given below:

$$L_q = -\text{log}\frac{\text{exp}(q⋅ k_{+} / \tau)}{\sum_{i=0}^k \text{exp}(q ⋅ k_{i} / \tau)}$$

where $\tau$ is a _temperature_ hyper-parameter.

<img class="image image--xl" src="/assets/img/moco.png"/>

## BYOL

![BYOL](/assets/img/byol.png)
(Grill et al., 2020)

## SwAV

(Caron et al., 2020)

## SimSiam

(Chen and He, 2021)

## References

- Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P. and Joulin, A., 2020. Unsupervised learning of visual features by contrasting cluster assignments. _Advances in neural information processing systems_, 33, pp.9912-9924.

- Chen, X. and He, K., 2021. Exploring simple siamese representation learning. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_ (pp. 15750-15758).

- Grill, J.B., Strub, F., Altché, F., Tallec, C., Richemond, P., Buchatskaya, E., Doersch, C., Avila Pires, B., Guo, Z., Gheshlaghi Azar, M. and Piot, B., 2020. Bootstrap your own latent-a new approach to self-supervised learning. _Advances in neural information processing systems_, 33, pp.21271-21284.

- He, K., Fan, H., Wu, Y., Xie, S. and Girshick, R., 2020. Momentum contrast for unsupervised visual representation learning. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_ (pp. 9729-9738).